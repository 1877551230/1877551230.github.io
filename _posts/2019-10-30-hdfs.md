---
layout:     post
title:      HDFS
subtitle:   
date:       2019-10-24
categories: 大数据
author:     miracle
catalog: true
tags:
    - hdfs
---

* content
{:toc}


大数据概述
概述:
一:6V 
1. 数据体量大 
2. 数据种类样式多
3. 数据的增长速度越来越快
4. 数据的价值密度低
5. 数据的真实性
6. 数据的连通性
7. 数据的动态性,可视化,合法性

## Hadoop

### 概述
1. Hadoop是Apache提供的一套开源的,可靠地,可扩展的,用于进行分布式存储和计算的框架
### 发展历程
1. 创始人:Doug Cutting和Mike Caferalla
2. 在2002年,doug和mike设计一套搜索引擎Nutch,爬取了全网十亿个网页数据
3. 在2003年,Google发表了一篇论文the google file system,阐述了分布式存储的原理,但是google并没有公开这个框架,Doug根据这篇论文设计实现了NDFS
4. 在2004年,google发表了一篇论文,google MapReduce,阐述了分布式计算的原理,doug根据这个论文设计实现了MapReduce
5. 在nutch0.8版本的时候,将ndfs和MapReduce从nutch中分离出来,形成了Hadoop,将ndfs更名为hdfs
6. 在2007年,doug携带hadoop入职了Yahoo
7. 在雅虎工作期间,主持设计了HBase,Pig等框架
8. 雅虎将hadoop等框架贡献给了Apache

### 模块

1. Hadoop Common:基本模块,用于支持其他模块
2. Hadoop Distributed File System:分布式存储框架
3. Hadoop yarn:任务调度和集群资源管理
4. Hadoop MapReduce:分布式计算
5. Hadoop Ozone:对象存储
6. hadoop submarine:机器学习引擎 

### 版本
1.0和2.0不兼容
1. 1.0:common,hdfs,MapReduce
2. 2.0:common,hdfs,MapReduce,yarn
3. 3.0::common,hdfs,MapReduce,yarn,ozone,最新版包含submarine

## HDFS:

### 简述
1. HDFS是hadoop中用于进行数据分布式存储的模块

### 细节:

1. HDFS中,存储数据的时候会将数据切块,每一个块称为Block  
2. HDFS中,主要包含两个重要的进行NameNode和DataNode.  
 a. NameNode用于管理节点和记录元数据(metaData);  
 b. DataNode用于存储数据  
3. HDFS中会对数据自动进行备份,称之为副本(replication).如果不指定,默认副本数量为3(额外复制两次,加上原数据构成三个).
4. HDFS仿照linux设计了一套文件存储系统
### Block
1. 在HDFS中,数据都是以block为单位进行存储的
2. 默认情况下,Block的大小是128M,通过dfs.block来调节大小
3. 如果一个文件,不足一个Block大小,这个文件整体作为一个Block存储,并且Block大小和文件大小一致
4. 会给每一个Block一个编号,BlockId,通过BlockId,能够确定Block的顺序
5. 同一个Block的不同副本一定是在不同节点上,不同Block的副本可能在同一个节点上
6. Block的意义:
 a. 为了能够存储超大文件  
 b. 为了进行快速备份

### NameNode
1. NameNode是HDFS的核心节点,用于管理DataNode以及存储元数据
2. 元数据主要包含:
 a. 文件的存储路径  
 b. 文件权限  
 c. 文件大小以及块的大小  
 d. BlockId  
 e. Block的存储节点  
 f. 副本数量  
3. NameNode会将元数据存储在内存中以及磁盘中
 a. 存储在内存中的目的是为了快速查询  
 b. 存储在磁盘中为了崩溃恢复  
4. 元数据的存储路径由hadoop.tmp.dir来决定
5. 元数据的存储文件:
 a. edits:纪录写操作的文件  
 b. fsimage:映像文件,记录元数据,但是这个文件中的元数据和内存中的元数据并不是同步的,fsimage中的元数据往往是落后于内存中的元数据
6. NameNode在接收到写操作的时候,先将这个操作记录到edits_inprogress文件中,如果记录成功,则更改内存中的元数据,内存中的元数据更改成功之后,会给客户端返回成功信号,这样设计目的是为了保证操作的可靠,只要记录成功了,这个操作就一定会执行.
7. 当fsiamge进行更新的时候,将edits文件中的操作一一取出,重新执行到fsimage中.此时edits-inprogress文件会滚动成edits文件,同时生成一个新的edits_inprogress用于纪录新的操作
8. fsimage更新/edits滚动的触发条件:
 a. 空间:当edits文件达到指定大小(默认是64M,可以通过fs.checkpoint.size设置)时,触发edits-inprogress文件的滚动  
 b. 时间:当距离上次滚动间隔指定时间(默认是3600s,可以通过fs.checkpoint.period来调节)之后,会触发edits文件的滚动  
 c. 重启:当NameNode重启的时候,会触发edits文件的滚动  
 d. 强制:通过hadoop dfsadmin -rollEdits命令来强制edits文件滚动
9. DataNode会通过心跳机制向NameNode注册管理,DataNode会定时发送心跳给NameNode
10. DataNode每隔3s给NameNode发送一次心跳,心跳是通过rpc机制发送
11. 心跳信息:
 a. 当前DataNode中的BlockId  
 b. 当前DataNode的状态  (预服役,服役,预退役)  
12. NameNode如果在10min内没有收到DataNode的心跳,则认为这个DataNode已经lost,会将这个节点上的数据备份放到其他节点上,保证整个集群的副本数量
13. NameNode重新启动后,进行fsimage文件的更新/edits文件的滚动,将fsimage文件的内容加载到内存中,等待DataNode的心跳,如果在指定的时间内没有等到心跳,则认为这个DataNode已经丢失,需要对应处理,如果等到心跳,那么NameNode对DataNode的数据进行校验,校验DataNode中的数据和元数据中的记录是否一致,如果校验失败,会试图恢复这个数据,恢复之后,会再次校验,如果校验成功就对外提供服务,退出安全模式,如果校验失败则重新恢复重新校验,这个过程称为安全模式
14. 安全模式中,hdfs集群只对外提供读服务
15. 因为安全模式的校验问题,要求副本数量不能多于节点数量
16. 如果在合理的时间内,集群没有自动退出安全模式,那么可能已经产生了数据丢失并且数据不可恢复
17. 强制退出安全模式:hadoop dfsadmin -safemode leave

### 副本放置策略

1. 第一个副本: 
 a. 如果是集群内部上传,谁上传第一个副本就在谁身上  
 b. 如果是集群外部上传,则第一个副本会放在相对空闲的节点上  
2. 第二个副本:
 a. 在hadoop2.7之前:第二个副本是放在和第一个副本不同机架的节点上  
 b. 从hadoop2.7开始:第二个副本是放在和第一个副本相同机架的节点上
3. 第三个副本:
 a. 在hadoop2.7之前,第三个副本是放在和第二个副本相同机架的节点上
 b. 从hadoop2.7开始:第三个副本是放在和第二个副本不同机架的节点上
4. 更多副本:谁闲放在谁身上

### 机架感知策略
1. 所谓的机架不是物理机架而是逻辑机架,本质上就是一个映射
2. 可以将不同物理机架的节点映射到同一个逻辑机架上
3. 实际过程中会将同一个物理机架的节点映射到同一个逻辑机架上 

### DataNode
1. 存储Block
2. DataNode会给NameNode发送心跳
3. 存储Block的路径是有hadoop.tmp.dir属性来指定 

### SecondaryNameNode

1. 不是NameNode的备份,作用辅助NameNode完成edits文件的滚动
2. 在完全分布式中,一旦出现SecondaryNameNode,则edits文件的滚动是在SecondaryNameNode上进行,如果没有SecondaryNameNode,则edits文件的滚动由NameNode自己完成
3. 在hdfs集群中,只能采取NameNode+SecondaryNameNode结构或是双NameNode结构,因为secondaryNameNode的作用可以被NameNode取代,但是NameNode作为核心节点如果只有1个容易出现单点故障,所以实际过程中往往会舍弃secondaryNameNode采用双NameNode结构来构成NameNode的HA(high available)

### 回收站机制

1. HDFS回收站机制默认是不开启的,修改配置可以开启

### DFS目录
1. dfs目录是在NameNode格式化的时候出现的
2. in_user.lock用于标记当前节点已经开启了对应进程
3. hdfs在第一次启动的时候,1min之后会自动进行一次edits文件的滚动
4. 在hdfs中,会对每一次的写操作分配一个全局递增的编号,编号称为事务id txid
5. 在hdfs中,将开始记录日志和结束记录日志看作是一个写操作,每一个edits文件的开头和结尾都是OP-START-LOG-SEGMENT和OP-END-LOG-SEGMENT和
6. 上传文件:
 a. OP_ADD:在HDFS上创建一个文件名 -.COPYING-文件  
 b. OP_ALLOCATE-BLOCK-ID:分配blockId  
 c. OP-SET-GENSTAMP-v2:设置时间戳编号  
 d. OP-ADD-BLOCK:给文件添加块 上传数据  
 e. OP-CLOSE:关流,关闭文件
7. 文件在上传完成后不能改变
8. md5文件是为了防止fsimage文件被篡改的,对fsimage文件进行校验
9. version:
 a. clusterId-集群编号.在NameNode格式化的时候自动计算产生的,也就意味着NameNode每格式化一次,clusterId就会重新计算,NameNode会将clusterId分发给每一个DataNode,DataNode也只接收一次,  

### 联邦HDFS:
用多个节点来取代一个NameNode,需要将路径固定,每一个路径要对应一个节点,优势在于能够有效的提高并发量,但是劣势在于路径不能改变,加重了DataNode的负担,加重了网络负担,要求处于同一个联邦的NameNode的BlockPoolId要一致

### 流程

#### 读流程/下载

1. 客户端发起RPC请求到NameNode
2. NameNode在接受到请求后会进行校验这个文件是否存在
3. 如果文件存在,那么NameNode会读取元数据,给客户端一个信号
4. 客户端向NameNode要第一个Block的地址
5. NameNode收到请求后会读取元数据,将第一个Block的地址放入队列中返回给客户端
6. 客户端收到队列后从中选择一个较近的节点来读取第一个Block,读取完成后,会对这个Block进行一次checksum的验证,如果校验失败,客户端会给NameNode一个信号,然后重新选取地址重新读取,如果校验成功,则客户端会向NameNode要第二个Block的地址,重复4,5,6三步
7. 客户端读取完成所有的Block之后,会给NameNode一个结束信号,NameNode在收到信号之后会关闭文件

#### 写入流程/上传

1. 客户端发起RPC请求到NameNode
2. NameNode在接受到请求后会进行校验:
 a. 校验指定路径是否存在  
 b. 校验写入路径是否有权限  
 c. 校验指定路径中是否有同名文件  
3. 如果校验失败则抛出异常;如果校验成功,记录元数据,NameNode会给客户端一个信号
4. 客户端在收到信号之后会向NameNode要第一个Block的存储位置
5. NameNode在收到请求之后,会等待心跳,选取DataNode的地址,放入队列中,返回给客户端.默认情况下,NameNode会选择3个地址
6. 客户端收到队列后取出三个地址,从这些地址中选择一个较近的节点写入第一个Block的第一个副本
7. 第一个副本所在节点会通过pipeline(管道,实际上是NIO中的channel)将第二个副本写到其他节点上,第二个副本所在的节点再写第三个副本
8. 写完之后,第三个副本所在的节点会给第二个副本所在的节点返回ack,第二个副本所在的节点收到ack后会给第一个副本所在的节点返回ack,第一个副本所在的节点收到ack后会返回给客户端
9. 写完第一个Block之后,客户端会和NameNode要第二个Block的存储位置,然后重复5,6,7,8的过程
10. 当写完所有的Block之后,客户端会给NameNode一个结束信号,NameNode就会关闭文件/关流,文件关闭之后,这个文件就不可修改

#### 删除流程

1. 客户端发起RPC请求到NameNode
2. NameNode在收到请求之后,会将这个请求记录到edits文件中,然后更新内存中的元数据,内存更新成功之后会给客户端返回一个ack信号,此时这个文件对应的Block依然存储在DataNode
3. 在NameNode收到DataNode的心跳的时候,NameNode就会检查Block信息,会给DataNode进行心跳响应,要求删除相应的Block,DataNode在收到心跳响应之后才会真正删除Block


## 特点:

1. 能够存储超大文件 分布式+切块
2. 能够快速应对和检测故障 心跳
3. 高可用 副本+双NameNode
4. 能够动态扩展在廉价机器上 横向扩展
5. 不支持低延迟响应
6. 不建议存储小文件 每一个小文件会对应一条元数据,大量小文件会产生大量元数据,会导致元数据的查询效率变慢
7. 简化的一致性模型 允许一次写入多次读取
8. hdfs不支持事务














